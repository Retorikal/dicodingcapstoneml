{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import itertools\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "\n",
    "MAX_HISTORY = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load both dataset and convert to tfds object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load courses list\n",
    "TODO: Course list disini sepertinya rada galengkap, token dari course\" bangkit jadi nol semua\n",
    "\n",
    "Output berupa objek MapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name        : Belajar Fundamental Aplikasi Android\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses = pd.read_csv(\"courses.csv\")\n",
    "unique_course_names = courses[\"name\"].tolist()\n",
    "unique_course_set = set(unique_course_names)\n",
    "\n",
    "courses_dict = {\n",
    "  \"course_name\": np.array(unique_course_names)\n",
    "}\n",
    "\n",
    "for example in slices(courses_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break\n",
    "\n",
    "tfds_courses = tf.data.Dataset.from_tensor_slices(courses_dict)\n",
    "tfdsmap_courses = tfds_courses.map(lambda x: x['course_name'])\n",
    "tfdsmap_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Belajar Fundamental Aplikasi Android': 1,\n",
       " 'Belajar Membangun LINE Chatbot': 2,\n",
       " 'Belajar Membuat Aplikasi Android untuk Pemula': 3,\n",
       " 'Memulai Pemrograman Dengan Java': 4,\n",
       " 'Memulai Pemrograman Dengan Kotlin': 5,\n",
       " 'Menjadi Azure Cloud Developer': 6,\n",
       " 'Memulai Pemrograman Dengan Python': 7,\n",
       " 'Memulai Pemrograman Dengan C': 8,\n",
       " 'Belajar Dasar Pemrograman Web': 9,\n",
       " 'Menjadi Google Cloud Engineer': 10,\n",
       " 'Belajar Dasar-Dasar Azure Cloud': 11,\n",
       " 'Memulai Pemrograman Dengan Swift': 12,\n",
       " 'Belajar Membangun LINE Front-end Framework (LIFF)': 13,\n",
       " 'Belajar Membuat Aplikasi Flutter untuk Pemula': 14,\n",
       " 'Belajar Fundamental Front-End Web Development': 15,\n",
       " 'Menjadi Android Developer Expert': 16,\n",
       " 'Belajar Prinsip Pemrograman SOLID': 17,\n",
       " 'Belajar Membuat Aplikasi iOS untuk Pemula': 18,\n",
       " 'Belajar Dasar Visualisasi Data': 19,\n",
       " 'Belajar Machine Learning untuk Pemula': 20,\n",
       " 'Belajar Pengembangan Machine Learning': 21,\n",
       " 'Memulai Pemrograman Dengan Dart': 22,\n",
       " 'Belajar Fundamental Aplikasi Flutter': 23,\n",
       " 'Menjadi Flutter Developer Expert': 24,\n",
       " 'Belajar Fundamental Aplikasi iOS': 25,\n",
       " 'Menjadi iOS Developer Expert': 26,\n",
       " 'Menjadi Front-End Web Developer Expert': 27,\n",
       " 'Memulai Dasar Pemrograman untuk Menjadi Pengembang Software': 28,\n",
       " 'Cloud Practitioner Essentials (Belajar Dasar AWS Cloud)': 29,\n",
       " 'Belajar Dasar Pemrograman JavaScript': 30,\n",
       " 'Belajar Membuat Aplikasi Back-End untuk Pemula': 31,\n",
       " 'Architecting on AWS (Membangun Arsitektur Cloud di AWS)': 32,\n",
       " 'Belajar Fundamental Aplikasi Back-End': 33,\n",
       " 'Menjadi Back-End Developer Expert': 34,\n",
       " 'Meniti Karier sebagai Software Developer': 35,\n",
       " 'Pengenalan Data pada Pemrograman (Data 101)': 36,\n",
       " 'Pengenalan ke Logika Pemrograman (Programming Logic 101)': 37,\n",
       " 'Belajar Membuat Augmented Reality dengan Lens Studio': 38,\n",
       " 'Belajar Membuat Front-End Web untuk Pemula': 39,\n",
       " 'Belajar Dasar Git dengan GitHub': 40,\n",
       " 'Machine Learning Terapan': 41,\n",
       " 'Evaluasi Penguasaan Machine Learning': 42,\n",
       " 'Menjadi Google Cloud Architect': 43,\n",
       " 'Belajar Dasar UX Design': 44,\n",
       " 'Belajar Dasar Google Cloud': 45,\n",
       " 'Belajar Membuat Aplikasi Back-End untuk Pemula dengan Google Cloud': 46,\n",
       " 'Belajar Pengembangan Aplikasi Android Intermediate': 47,\n",
       " 'Belajar Jaringan Komputer untuk Pemula': 48}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_tokenizer_dict(train_list):\n",
    "  return dict(zip(train_list, [i+1 for i in range(len(train_list))]))\n",
    "\n",
    "get_tokenizer_dict(unique_course_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taken_courses      : ['Belajar Fundamental Aplikasi Android']\n",
      "recommendation     : Belajar Dasar Pemrograman Web\n"
     ]
    }
   ],
   "source": [
    "# Load and clean data\n",
    "useract = pd.read_csv(\"user_activities.csv\")\n",
    "useract = useract.drop(columns=['id'])\n",
    "useract = useract.dropna(how='all')\n",
    "\n",
    "def mergeall(rowdata):\n",
    "    aggregated_datas = \",\".join([str(s) for s in list(rowdata.values) if not pd.isna(s)])\n",
    "    return aggregated_datas.split(\",\")\n",
    "\n",
    "def mergecourse(rowdata):\n",
    "    aggregated_datas = \",\".join([str(s) for s in [rowdata.graduated_courses, rowdata.on_progress_courses] if not pd.isna(s)])\n",
    "    return aggregated_datas.split(\",\")\n",
    "\n",
    "merged_datas = list(useract.apply(mergeall, axis = 1))\n",
    "merged_courses = list(useract.apply(mergecourse, axis = 1))\n",
    "\n",
    "agumented_datas_dict = {\n",
    "  'taken_courses': [],\n",
    "  'recommendation': []\n",
    "}\n",
    "\n",
    "# for each merged course, \n",
    "#   for each course in merged course,\n",
    "#     pick 1 as output, lainya jadi input\n",
    "#     push as new entry\n",
    "# TODO: \n",
    "#   This split is not too well-defined on merged courses with length longer than MAX_HISTORY.\n",
    "#   This is because after permutating possible input, trailing courses are cut off at token padding anyway.\n",
    "\n",
    "for i in range(len(merged_datas)):\n",
    "  merged_data = merged_datas[i]\n",
    "  merged_course = [course for course in merged_courses[i] if course in unique_course_set] \n",
    "  \n",
    "  # Sliding window sebesar MAX_HISTORY + 1 untuk dimasukkan permutasi output\n",
    "  for j in range(max(len(merged_course)-MAX_HISTORY+2, 1)):\n",
    "    merged_course_window = merged_course[j: min(len(merged_course), MAX_HISTORY + j +1)]\n",
    "\n",
    "    # Permutasi data dalam window sebagai output. Untuk setiap n dalam S, Input: S-exclude-n, Output: n \n",
    "    for course in merged_course_window:\n",
    "      #Simpen dulu buat nanti kalo mau ditambahin ingfo non-courses\n",
    "      #agumented_datas_dict['x'].append([data for data in merged_data if data != course])\n",
    "      x = [data for data in merged_course_window if data != course]\n",
    "      y = course\n",
    "      agumented_datas_dict['taken_courses'].append(x)\n",
    "      agumented_datas_dict['recommendation'].append(y)\n",
    "\n",
    "for example in slices(agumented_datas_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load user activities list\n",
    "User Activities merujuk pada semua course yang pernah dan sedang diambil. Asumsinya adalah kalau banyak user yang ambil bebarengan, maka seharusnya course\" tsb berkaitan.\n",
    "\n",
    "Augmentasi data dilakukan sbb:\n",
    "```\n",
    "Jika course yang pernah diambil adalah [a, b, c, d, e]\n",
    "output akan diaugmentasi menjadi:\n",
    "x             | y\n",
    "--------------+----\n",
    "[a, b, c, d]  | e\n",
    "[a, b, c, e]  | d\n",
    "[a, b, d, e]  | c\n",
    "[a, c, d, e]  | b\n",
    "[b, c, d, e]  | a\n",
    "\n",
    "```\n",
    "\n",
    "Output berupa objek MapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taken_courses      : [0 0 0 0 1]\n",
      "recommendation     : Belajar Dasar Pemrograman Web\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'taken_courses': TensorSpec(shape=(5,), dtype=tf.int32, name=None), 'recommendation': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize manual karena usecasenya agak aneh\n",
    "\n",
    "def get_tokenizer_dict(train_list):\n",
    "  return dict(zip(train_list, [i+1 for i in range(len(train_list))]))\n",
    "\n",
    "def pad_tokens(input_sequences, maxlen):\n",
    "  return np.array(pad_sequences(input_sequences, maxlen=maxlen, padding='pre'))\n",
    "\n",
    "def tokenize(tokenizer_dict, corpus, maxlen = 5):\n",
    "  output = []\n",
    "  for line in corpus:\n",
    "    tokenizedline = [tokenizer_dict.get(entry, 0) for entry in line]\n",
    "    output.append(tokenizedline)\n",
    "    \n",
    "  return pad_tokens(output, maxlen)\n",
    "\n",
    "\n",
    "tokenizer_dict = get_tokenizer_dict(unique_course_names)\n",
    "tokenized_datas = tokenize(tokenizer_dict, agumented_datas_dict[\"taken_courses\"], MAX_HISTORY)\n",
    "tokenized_datas_dict = {\n",
    "  'taken_courses': tokenized_datas,\n",
    "  'recommendation': agumented_datas_dict[\"recommendation\"]\n",
    "}\n",
    "\n",
    "for example in slices(tokenized_datas_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break\n",
    "\n",
    "tfds_tokenized_data = tf.data.Dataset.from_tensor_slices(tokenized_datas_dict)\n",
    "tfdsmap_tokenized_data = tfds_tokenized_data.map(lambda x: {\n",
    "  'taken_courses': x['taken_courses'],\n",
    "  'recommendation': x['recommendation']\n",
    "})\n",
    "tfdsmap_tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "2881\n"
     ]
    }
   ],
   "source": [
    "print(len(tfdsmap_courses))\n",
    "print(len(tfdsmap_tokenized_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec={'taken_courses': TensorSpec(shape=(5,), dtype=tf.int32, name=None), 'recommendation': TensorSpec(shape=(), dtype=tf.string, name=None)}> 2592\n",
      "<TakeDataset element_spec={'taken_courses': TensorSpec(shape=(5,), dtype=tf.int32, name=None), 'recommendation': TensorSpec(shape=(), dtype=tf.string, name=None)}> 289\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42069)\n",
    "shuffled = tfdsmap_tokenized_data.shuffle(len(tfdsmap_tokenized_data), seed=42069, reshuffle_each_iteration=False)\n",
    "\n",
    "train_len = math.floor(len(tfdsmap_tokenized_data) * 0.9)\n",
    "test_len = len(tfdsmap_tokenized_data) - train_len\n",
    "\n",
    "train = shuffled.take(train_len)\n",
    "test = shuffled.skip(train_len).take(test_len)\n",
    "\n",
    "print(train, len(train))\n",
    "print(test, len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "#https://www.tensorflow.org/recommenders/examples/multitask/\n",
    "\n",
    "user_properties_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(len(unique_course_names)+1, 32, input_length=MAX_HISTORY),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(embedding_dimension, activation='relu')\n",
    "])\n",
    "\n",
    "course_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(vocabulary=unique_course_names, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_course_names) + 1, embedding_dimension),\n",
    "])\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=tfrs.metrics.FactorizedTopK(\n",
    "    candidates=tfdsmap_courses.batch(16).map(course_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tfrs.Model):\n",
    "  def __init__(self, user_model, course_model):\n",
    "    super().__init__()\n",
    "    self.course_model: tf.keras.Model = course_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[tf.Tensor, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"taken_courses\"])\n",
    "\n",
    "    # And pick out the course features and pass them into the course model,\n",
    "    # getting embeddings back.\n",
    "    positive_course_embeddings = self.course_model(features[\"recommendation\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_course_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 5, 32)             1568      \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 160)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 150)               24150     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                3232      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,700\n",
      "Trainable params: 66,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " string_lookup_6 (StringLook  (None,)                  0         \n",
      " up)                                                             \n",
      "                                                                 \n",
      " embedding_13 (Embedding)    (None, 32)                1568      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,568\n",
      "Trainable params: 1,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(user_properties_model, course_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.15))\n",
    "\n",
    "cached_train = train.shuffle(len(tfdsmap_tokenized_data)).batch(400).cache()\n",
    "cached_test = test.batch(40).cache()\n",
    "\n",
    "user_properties_model.summary()\n",
    "course_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "7/7 [==============================] - 1s 41ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0451 - factorized_top_k/top_5_categorical_accuracy: 0.0999 - factorized_top_k/top_10_categorical_accuracy: 0.1717 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 2588.9838 - regularization_loss: 0.0000e+00 - total_loss: 2588.9838\n",
      "Epoch 2/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0266 - factorized_top_k/top_5_categorical_accuracy: 0.1412 - factorized_top_k/top_10_categorical_accuracy: 0.2157 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 2051.6808 - regularization_loss: 0.0000e+00 - total_loss: 2051.6808\n",
      "Epoch 3/70\n",
      "7/7 [==============================] - 0s 44ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0405 - factorized_top_k/top_5_categorical_accuracy: 0.2276 - factorized_top_k/top_10_categorical_accuracy: 0.2878 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 2049.7035 - regularization_loss: 0.0000e+00 - total_loss: 2049.7035\n",
      "Epoch 4/70\n",
      "7/7 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0467 - factorized_top_k/top_5_categorical_accuracy: 0.1836 - factorized_top_k/top_10_categorical_accuracy: 0.2569 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 2019.2955 - regularization_loss: 0.0000e+00 - total_loss: 2019.2955\n",
      "Epoch 5/70\n",
      "7/7 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0621 - factorized_top_k/top_5_categorical_accuracy: 0.2577 - factorized_top_k/top_10_categorical_accuracy: 0.3453 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1986.6625 - regularization_loss: 0.0000e+00 - total_loss: 1986.6625\n",
      "Epoch 6/70\n",
      "7/7 [==============================] - 0s 44ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0660 - factorized_top_k/top_5_categorical_accuracy: 0.2758 - factorized_top_k/top_10_categorical_accuracy: 0.3557 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1987.3833 - regularization_loss: 0.0000e+00 - total_loss: 1987.3833\n",
      "Epoch 7/70\n",
      "7/7 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0806 - factorized_top_k/top_5_categorical_accuracy: 0.2724 - factorized_top_k/top_10_categorical_accuracy: 0.3414 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1976.5878 - regularization_loss: 0.0000e+00 - total_loss: 1976.5878\n",
      "Epoch 8/70\n",
      "7/7 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0421 - factorized_top_k/top_5_categorical_accuracy: 0.2851 - factorized_top_k/top_10_categorical_accuracy: 0.3704 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1968.9093 - regularization_loss: 0.0000e+00 - total_loss: 1968.9093\n",
      "Epoch 9/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0702 - factorized_top_k/top_5_categorical_accuracy: 0.2643 - factorized_top_k/top_10_categorical_accuracy: 0.3565 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1981.5903 - regularization_loss: 0.0000e+00 - total_loss: 1981.5903\n",
      "Epoch 10/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0621 - factorized_top_k/top_5_categorical_accuracy: 0.2901 - factorized_top_k/top_10_categorical_accuracy: 0.3819 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1960.8977 - regularization_loss: 0.0000e+00 - total_loss: 1960.8977\n",
      "Epoch 11/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0637 - factorized_top_k/top_5_categorical_accuracy: 0.3071 - factorized_top_k/top_10_categorical_accuracy: 0.3997 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1982.9447 - regularization_loss: 0.0000e+00 - total_loss: 1982.9447\n",
      "Epoch 12/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0571 - factorized_top_k/top_5_categorical_accuracy: 0.2832 - factorized_top_k/top_10_categorical_accuracy: 0.3804 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1970.8315 - regularization_loss: 0.0000e+00 - total_loss: 1970.8315\n",
      "Epoch 13/70\n",
      "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0845 - factorized_top_k/top_5_categorical_accuracy: 0.3121 - factorized_top_k/top_10_categorical_accuracy: 0.4032 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1950.6759 - regularization_loss: 0.0000e+00 - total_loss: 1950.6759\n",
      "Epoch 14/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0880 - factorized_top_k/top_5_categorical_accuracy: 0.3353 - factorized_top_k/top_10_categorical_accuracy: 0.4387 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1930.0079 - regularization_loss: 0.0000e+00 - total_loss: 1930.0079\n",
      "Epoch 15/70\n",
      "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0868 - factorized_top_k/top_5_categorical_accuracy: 0.3391 - factorized_top_k/top_10_categorical_accuracy: 0.4618 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1929.7036 - regularization_loss: 0.0000e+00 - total_loss: 1929.7036\n",
      "Epoch 16/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0517 - factorized_top_k/top_5_categorical_accuracy: 0.3395 - factorized_top_k/top_10_categorical_accuracy: 0.4583 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1934.6781 - regularization_loss: 0.0000e+00 - total_loss: 1934.6781\n",
      "Epoch 17/70\n",
      "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0841 - factorized_top_k/top_5_categorical_accuracy: 0.3179 - factorized_top_k/top_10_categorical_accuracy: 0.4529 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1921.6382 - regularization_loss: 0.0000e+00 - total_loss: 1921.6382\n",
      "Epoch 18/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0772 - factorized_top_k/top_5_categorical_accuracy: 0.3503 - factorized_top_k/top_10_categorical_accuracy: 0.4888 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1903.8804 - regularization_loss: 0.0000e+00 - total_loss: 1903.8804\n",
      "Epoch 19/70\n",
      "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0737 - factorized_top_k/top_5_categorical_accuracy: 0.3438 - factorized_top_k/top_10_categorical_accuracy: 0.4815 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1915.7518 - regularization_loss: 0.0000e+00 - total_loss: 1915.7518\n",
      "Epoch 20/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0910 - factorized_top_k/top_5_categorical_accuracy: 0.3565 - factorized_top_k/top_10_categorical_accuracy: 0.5046 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1898.6090 - regularization_loss: 0.0000e+00 - total_loss: 1898.6090\n",
      "Epoch 21/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0741 - factorized_top_k/top_5_categorical_accuracy: 0.3754 - factorized_top_k/top_10_categorical_accuracy: 0.5343 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1886.3181 - regularization_loss: 0.0000e+00 - total_loss: 1886.3181\n",
      "Epoch 22/70\n",
      "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0826 - factorized_top_k/top_5_categorical_accuracy: 0.3542 - factorized_top_k/top_10_categorical_accuracy: 0.5197 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1874.7687 - regularization_loss: 0.0000e+00 - total_loss: 1874.7687\n",
      "Epoch 23/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0941 - factorized_top_k/top_5_categorical_accuracy: 0.3569 - factorized_top_k/top_10_categorical_accuracy: 0.5282 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1883.8887 - regularization_loss: 0.0000e+00 - total_loss: 1883.8887\n",
      "Epoch 24/70\n",
      "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0779 - factorized_top_k/top_5_categorical_accuracy: 0.4124 - factorized_top_k/top_10_categorical_accuracy: 0.5922 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1848.7641 - regularization_loss: 0.0000e+00 - total_loss: 1848.7641\n",
      "Epoch 25/70\n",
      "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1123 - factorized_top_k/top_5_categorical_accuracy: 0.4352 - factorized_top_k/top_10_categorical_accuracy: 0.6169 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1832.5489 - regularization_loss: 0.0000e+00 - total_loss: 1832.5489\n",
      "Epoch 26/70\n",
      "7/7 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1080 - factorized_top_k/top_5_categorical_accuracy: 0.4252 - factorized_top_k/top_10_categorical_accuracy: 0.5949 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1860.3236 - regularization_loss: 0.0000e+00 - total_loss: 1860.3236\n",
      "Epoch 27/70\n",
      "7/7 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1088 - factorized_top_k/top_5_categorical_accuracy: 0.4452 - factorized_top_k/top_10_categorical_accuracy: 0.6119 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1842.2568 - regularization_loss: 0.0000e+00 - total_loss: 1842.2568\n",
      "Epoch 28/70\n",
      "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1331 - factorized_top_k/top_5_categorical_accuracy: 0.5093 - factorized_top_k/top_10_categorical_accuracy: 0.6960 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1777.6657 - regularization_loss: 0.0000e+00 - total_loss: 1777.6657\n",
      "Epoch 29/70\n",
      "7/7 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1478 - factorized_top_k/top_5_categorical_accuracy: 0.5081 - factorized_top_k/top_10_categorical_accuracy: 0.6960 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1768.5657 - regularization_loss: 0.0000e+00 - total_loss: 1768.5657\n",
      "Epoch 30/70\n",
      "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1200 - factorized_top_k/top_5_categorical_accuracy: 0.5216 - factorized_top_k/top_10_categorical_accuracy: 0.7029 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1772.4857 - regularization_loss: 0.0000e+00 - total_loss: 1772.4857\n",
      "Epoch 31/70\n",
      "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1296 - factorized_top_k/top_5_categorical_accuracy: 0.5795 - factorized_top_k/top_10_categorical_accuracy: 0.7589 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1725.5396 - regularization_loss: 0.0000e+00 - total_loss: 1725.5396\n",
      "Epoch 32/70\n",
      "7/7 [==============================] - 0s 44ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1566 - factorized_top_k/top_5_categorical_accuracy: 0.6154 - factorized_top_k/top_10_categorical_accuracy: 0.7851 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1692.8418 - regularization_loss: 0.0000e+00 - total_loss: 1692.8418\n",
      "Epoch 33/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1748 - factorized_top_k/top_5_categorical_accuracy: 0.6065 - factorized_top_k/top_10_categorical_accuracy: 0.7812 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1702.4013 - regularization_loss: 0.0000e+00 - total_loss: 1702.4013\n",
      "Epoch 34/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1566 - factorized_top_k/top_5_categorical_accuracy: 0.6373 - factorized_top_k/top_10_categorical_accuracy: 0.7990 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1680.9156 - regularization_loss: 0.0000e+00 - total_loss: 1680.9156\n",
      "Epoch 35/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1709 - factorized_top_k/top_5_categorical_accuracy: 0.6373 - factorized_top_k/top_10_categorical_accuracy: 0.7998 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1683.4374 - regularization_loss: 0.0000e+00 - total_loss: 1683.4374\n",
      "Epoch 36/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1663 - factorized_top_k/top_5_categorical_accuracy: 0.6431 - factorized_top_k/top_10_categorical_accuracy: 0.8083 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1650.8930 - regularization_loss: 0.0000e+00 - total_loss: 1650.8930\n",
      "Epoch 37/70\n",
      "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1790 - factorized_top_k/top_5_categorical_accuracy: 0.6879 - factorized_top_k/top_10_categorical_accuracy: 0.8310 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1632.3487 - regularization_loss: 0.0000e+00 - total_loss: 1632.3487\n",
      "Epoch 38/70\n",
      "7/7 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1586 - factorized_top_k/top_5_categorical_accuracy: 0.6566 - factorized_top_k/top_10_categorical_accuracy: 0.8191 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1625.4956 - regularization_loss: 0.0000e+00 - total_loss: 1625.4956\n",
      "Epoch 39/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1983 - factorized_top_k/top_5_categorical_accuracy: 0.6833 - factorized_top_k/top_10_categorical_accuracy: 0.8372 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1593.6140 - regularization_loss: 0.0000e+00 - total_loss: 1593.6140\n",
      "Epoch 40/70\n",
      "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1863 - factorized_top_k/top_5_categorical_accuracy: 0.7365 - factorized_top_k/top_10_categorical_accuracy: 0.8684 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1536.2905 - regularization_loss: 0.0000e+00 - total_loss: 1536.2905\n",
      "Epoch 41/70\n",
      "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2307 - factorized_top_k/top_5_categorical_accuracy: 0.7508 - factorized_top_k/top_10_categorical_accuracy: 0.8777 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1523.9731 - regularization_loss: 0.0000e+00 - total_loss: 1523.9731\n",
      "Epoch 42/70\n",
      "7/7 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2346 - factorized_top_k/top_5_categorical_accuracy: 0.7392 - factorized_top_k/top_10_categorical_accuracy: 0.8646 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1552.0979 - regularization_loss: 0.0000e+00 - total_loss: 1552.0979\n",
      "Epoch 43/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2149 - factorized_top_k/top_5_categorical_accuracy: 0.7704 - factorized_top_k/top_10_categorical_accuracy: 0.8958 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1499.5621 - regularization_loss: 0.0000e+00 - total_loss: 1499.5621\n",
      "Epoch 44/70\n",
      "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2361 - factorized_top_k/top_5_categorical_accuracy: 0.7704 - factorized_top_k/top_10_categorical_accuracy: 0.8920 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1494.9524 - regularization_loss: 0.0000e+00 - total_loss: 1494.9524\n",
      "Epoch 45/70\n",
      "7/7 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2627 - factorized_top_k/top_5_categorical_accuracy: 0.7778 - factorized_top_k/top_10_categorical_accuracy: 0.8985 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1477.3465 - regularization_loss: 0.0000e+00 - total_loss: 1477.3465\n",
      "Epoch 46/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2577 - factorized_top_k/top_5_categorical_accuracy: 0.8025 - factorized_top_k/top_10_categorical_accuracy: 0.9043 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1452.1705 - regularization_loss: 0.0000e+00 - total_loss: 1452.1705\n",
      "Epoch 47/70\n",
      "7/7 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2458 - factorized_top_k/top_5_categorical_accuracy: 0.8194 - factorized_top_k/top_10_categorical_accuracy: 0.9263 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1403.3406 - regularization_loss: 0.0000e+00 - total_loss: 1403.3406\n",
      "Epoch 48/70\n",
      "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2708 - factorized_top_k/top_5_categorical_accuracy: 0.8291 - factorized_top_k/top_10_categorical_accuracy: 0.9248 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1391.8679 - regularization_loss: 0.0000e+00 - total_loss: 1391.8679\n",
      "Epoch 49/70\n",
      "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2446 - factorized_top_k/top_5_categorical_accuracy: 0.8148 - factorized_top_k/top_10_categorical_accuracy: 0.9167 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1443.0727 - regularization_loss: 0.0000e+00 - total_loss: 1443.0727\n",
      "Epoch 50/70\n",
      "7/7 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2423 - factorized_top_k/top_5_categorical_accuracy: 0.8299 - factorized_top_k/top_10_categorical_accuracy: 0.9240 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1403.4862 - regularization_loss: 0.0000e+00 - total_loss: 1403.4862\n",
      "Epoch 51/70\n",
      "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2704 - factorized_top_k/top_5_categorical_accuracy: 0.8611 - factorized_top_k/top_10_categorical_accuracy: 0.9410 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1352.0640 - regularization_loss: 0.0000e+00 - total_loss: 1352.0640\n",
      "Epoch 52/70\n",
      "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3021 - factorized_top_k/top_5_categorical_accuracy: 0.8673 - factorized_top_k/top_10_categorical_accuracy: 0.9468 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1328.2210 - regularization_loss: 0.0000e+00 - total_loss: 1328.2210\n",
      "Epoch 53/70\n",
      "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2828 - factorized_top_k/top_5_categorical_accuracy: 0.8711 - factorized_top_k/top_10_categorical_accuracy: 0.9533 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1309.6320 - regularization_loss: 0.0000e+00 - total_loss: 1309.6320\n",
      "Epoch 54/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3013 - factorized_top_k/top_5_categorical_accuracy: 0.8858 - factorized_top_k/top_10_categorical_accuracy: 0.9529 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1301.1779 - regularization_loss: 0.0000e+00 - total_loss: 1301.1779\n",
      "Epoch 55/70\n",
      "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3040 - factorized_top_k/top_5_categorical_accuracy: 0.8789 - factorized_top_k/top_10_categorical_accuracy: 0.9579 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1299.6598 - regularization_loss: 0.0000e+00 - total_loss: 1299.6598\n",
      "Epoch 56/70\n",
      "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3214 - factorized_top_k/top_5_categorical_accuracy: 0.8846 - factorized_top_k/top_10_categorical_accuracy: 0.9572 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1295.9833 - regularization_loss: 0.0000e+00 - total_loss: 1295.9833\n",
      "Epoch 57/70\n",
      "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3499 - factorized_top_k/top_5_categorical_accuracy: 0.8943 - factorized_top_k/top_10_categorical_accuracy: 0.9653 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1280.0492 - regularization_loss: 0.0000e+00 - total_loss: 1280.0492\n",
      "Epoch 58/70\n",
      "7/7 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3461 - factorized_top_k/top_5_categorical_accuracy: 0.8989 - factorized_top_k/top_10_categorical_accuracy: 0.9657 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1259.2997 - regularization_loss: 0.0000e+00 - total_loss: 1259.2997\n",
      "Epoch 59/70\n",
      "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3430 - factorized_top_k/top_5_categorical_accuracy: 0.9120 - factorized_top_k/top_10_categorical_accuracy: 0.9703 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1241.0337 - regularization_loss: 0.0000e+00 - total_loss: 1241.0337\n",
      "Epoch 60/70\n",
      "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3337 - factorized_top_k/top_5_categorical_accuracy: 0.9109 - factorized_top_k/top_10_categorical_accuracy: 0.9699 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1242.6319 - regularization_loss: 0.0000e+00 - total_loss: 1242.6319\n",
      "Epoch 61/70\n",
      "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3410 - factorized_top_k/top_5_categorical_accuracy: 0.9059 - factorized_top_k/top_10_categorical_accuracy: 0.9684 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1246.5871 - regularization_loss: 0.0000e+00 - total_loss: 1246.5871\n",
      "Epoch 62/70\n",
      "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3592 - factorized_top_k/top_5_categorical_accuracy: 0.9155 - factorized_top_k/top_10_categorical_accuracy: 0.9726 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1243.6962 - regularization_loss: 0.0000e+00 - total_loss: 1243.6962\n",
      "Epoch 63/70\n",
      "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3349 - factorized_top_k/top_5_categorical_accuracy: 0.9132 - factorized_top_k/top_10_categorical_accuracy: 0.9718 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1244.6479 - regularization_loss: 0.0000e+00 - total_loss: 1244.6479\n",
      "Epoch 64/70\n",
      "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3858 - factorized_top_k/top_5_categorical_accuracy: 0.9171 - factorized_top_k/top_10_categorical_accuracy: 0.9753 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1249.5084 - regularization_loss: 0.0000e+00 - total_loss: 1249.5084\n",
      "Epoch 65/70\n",
      "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3368 - factorized_top_k/top_5_categorical_accuracy: 0.9255 - factorized_top_k/top_10_categorical_accuracy: 0.9796 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1218.4985 - regularization_loss: 0.0000e+00 - total_loss: 1218.4985\n",
      "Epoch 66/70\n",
      "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3673 - factorized_top_k/top_5_categorical_accuracy: 0.9317 - factorized_top_k/top_10_categorical_accuracy: 0.9850 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1202.9612 - regularization_loss: 0.0000e+00 - total_loss: 1202.9612\n",
      "Epoch 67/70\n",
      "7/7 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3619 - factorized_top_k/top_5_categorical_accuracy: 0.9348 - factorized_top_k/top_10_categorical_accuracy: 0.9853 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1193.8418 - regularization_loss: 0.0000e+00 - total_loss: 1193.8418\n",
      "Epoch 68/70\n",
      "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3777 - factorized_top_k/top_5_categorical_accuracy: 0.9398 - factorized_top_k/top_10_categorical_accuracy: 0.9846 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1189.2323 - regularization_loss: 0.0000e+00 - total_loss: 1189.2323\n",
      "Epoch 69/70\n",
      "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3823 - factorized_top_k/top_5_categorical_accuracy: 0.9387 - factorized_top_k/top_10_categorical_accuracy: 0.9838 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1184.3411 - regularization_loss: 0.0000e+00 - total_loss: 1184.3411\n",
      "Epoch 70/70\n",
      "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3704 - factorized_top_k/top_5_categorical_accuracy: 0.9421 - factorized_top_k/top_10_categorical_accuracy: 0.9842 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1183.5401 - regularization_loss: 0.0000e+00 - total_loss: 1183.5401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff48f086aa0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 33ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1557 - factorized_top_k/top_5_categorical_accuracy: 0.5156 - factorized_top_k/top_10_categorical_accuracy: 0.6505 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 234.9641 - regularization_loss: 0.0000e+00 - total_loss: 234.9641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.15570934116840363,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.5155709385871887,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.6505190134048462,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 1.0,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 1.0,\n",
       " 'loss': 11.986360549926758,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 11.986360549926758}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predicitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7ff4cb77a950>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "\n",
    "# recommends courses out of the entire courses dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((\n",
    "    tfdsmap_courses.batch(10), \n",
    "    tfdsmap_courses.batch(10).map(model.course_model)\n",
    "  ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]]\n",
      "Recommendation:\n",
      "Belajar Membuat Aplikasi Android untuk Pemula\n",
      "Memulai Pemrograman Dengan Java\n",
      "Belajar Fundamental Aplikasi Android\n",
      "Belajar Membangun LINE Chatbot\n",
      "Belajar Dasar Pemrograman Web\n"
     ]
    }
   ],
   "source": [
    "taken_courses = []\n",
    "inputdata = tokenize(tokenizer_dict, [taken_courses], MAX_HISTORY)\n",
    "print(inputdata)\n",
    "_, course_names = index(inputdata)\n",
    "print(\"Recommendation:\")\n",
    "for course_name in course_names[0, :5]:\n",
    "  tf.print(course_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29 35  9 32 40]]\n",
      "Recommendation:\n",
      "Menjadi Android Developer Expert\n",
      "Menjadi Flutter Developer Expert\n",
      "Memulai Dasar Pemrograman untuk Menjadi Pengembang Software\n",
      "Menjadi Front-End Web Developer Expert\n",
      "Menjadi Azure Cloud Developer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get recommendations.\n",
    "taken_courses = [\n",
    "  \"Cloud Practitioner Essentials (Belajar Dasar AWS Cloud)\",\n",
    "  \"Meniti Karier sebagai Software Developer\",\n",
    "  \"Belajar Dasar Pemrograman Web\",\n",
    "  \"Architecting on AWS (Membangun Arsitektur Cloud di AWS)\",\n",
    "  \"Belajar Dasar Git dengan GitHub\",\n",
    "]\n",
    "inputdata = tokenize(tokenizer_dict, [taken_courses], MAX_HISTORY)\n",
    "print(inputdata)\n",
    "\n",
    "_, course_names = index(inputdata)\n",
    "print(\"Recommendation:\")\n",
    "for course_name in course_names[0, :5]:\n",
    "  tf.print(course_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_index/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_index/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(index, \"./saved_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation:\n",
      "Belajar Fundamental Aplikasi iOS\n",
      "Memulai Pemrograman Dengan Swift\n",
      "Belajar Fundamental Aplikasi Back-End\n",
      "Memulai Pemrograman Dengan Dart\n",
      "Belajar Dasar Visualisasi Data\n"
     ]
    }
   ],
   "source": [
    "# load it back; can also be done in TensorFlow Serving.\n",
    "loaded = tf.saved_model.load(\"./saved_index\")\n",
    "\n",
    "# pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded(inputdata)\n",
    "\n",
    "_, course_names = loaded(inputdata)\n",
    "print(\"Recommendation:\")\n",
    "for course_name in course_names[0, :5]:\n",
    "  tf.print(course_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
